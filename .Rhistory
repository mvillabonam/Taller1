x = "Age",
y = "Log(Monthly Income Salary)",
subtitle = paste("Peak Age:", round(original_peak_age, 2),
"95% CI [",
round(peak_age_ci$percent[4], 2), ",",
round(peak_age_ci$percent[5], 2), "]")) +
theme_minimal()
gc(rm(list = ls()))
knitr::opts_chunk$set(echo = TRUE)
require(pacman)
p_load(stringr, # html to text
tidyverse, # tidy-data
skimr, # summary data
rvest, # Web scrapping
dplyr, # managing tables
corrplot,#Correlation plot
reshape2, # Long format for table
stargazer, # Latex tables
gridExtra, # visualizing missing data
furrr,
mosaic, # Bootstrap
gridExtra, #multiple graphs
boot,
car,
lmtest,
caret,
sandwich,
performance)
plan(multisession, workers = parallel::detectCores() - 1)
base <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_"
htmls <- paste0(base, "page_", 1:10, ".html")
scrape_table <- function(url) {
web_page <- read_html(url)
table <- web_page %>%
html_nodes("table.table-striped") %>%
html_table(fill = TRUE)
return(table[[1]])  # Extraer el primer elemento (que es la tabla real)
}
tables_list <- future_map(htmls, scrape_table)
db <- bind_rows(tables_list) %>% select(-...1)
plan(sequential)
db = bind_rows(tables_list) %>% select(-...1)
rm(web_page,table,base,htmls,url,scrape_table)
#--------------------FILTERING BY +18, EMPLOYED IN BOGOTÁ-----------------------
db2 <- db %>% filter(age > 18, ocu == 1, dominio == "BOGOTA" )
#------------ FRAMING MISSING VALUES -------------------------------------------
Nobs <- nrow(db2)
db_miss <- data.frame(
Variable = names(db2),
n_missing = colSums(is.na(db2)),
p_missing = round(colSums(100*is.na(db2))/Nobs,2)
)
rownames(db_miss) <- NULL
question <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/dictionary.html")
question <- question %>%
html_nodes("table") %>%
html_table(fill = TRUE)
question = bind_rows(question)
db_miss <- left_join(question, db_miss, by = "Variable")
db_miss <- db_miss %>% arrange(desc(p_missing)) %>% filter(p_missing != 0)
write.csv(db_miss, "1. Missing values per variable.csv", row.names = FALSE)
# SELECTING RELEVANT VARIABLES
db2 <- db2 %>%
select(y_ingLab_m, y_salary_m, y_total_m, ie,iees,
ingtotes, ingtotob, ingtot, y_bonificaciones_m, y_gananciaNeta_m,
y_gananciaNetaAgro_m, y_primaNavidad_m, y_primaServicios_m, y_primaVacaciones_m,
maxEducLevel, directorio, secuencia_p, orden, clase, dominio, mes, estrato1,
sex, age, oficio, fex_c, depto, fex_dpto, fweight,
informal,p6240,ocu,formal,informal,iees, imdi, impa, iof1, iof2, iof3h, iof6, isa,
iees, imdies, impaes,  iof1es, iof2es, iof3hes, iof3ies, iof6es, isaes,
cclasnr4, cclasnr5, cclasnr2, cclasnr6, cclasnr7, cclasnr8,
cclasnr11, cclasnr3,y_otros_m,y_vivienda_m,y_gananciaIndep_m)
#skim(db2)
#------------ DATA CLEANING PROCESS: CONSISTENCY -------------------------------
# P6240 to text for tables.
db2 <- db2 %>% mutate(Occupation = if_else(is.na(p6240), NA,
case_when(
p6240 == 6 ~ "Other activity",
p6240 == 5 ~ "Permanently unable to work",
p6240 == 4 ~ "Domestic work",
p6240 == 3 ~ "Studying",
p6240 == 2 ~ "Looking for work",
p6240 == 1 ~ "Working",
TRUE ~ as.character(p6240)
)))
# OCCUPIED = FORMAL + INFORMAL.
Occupied_description <- db2 %>%
group_by(Occupation) %>%
summarise(across(c(ocu, formal, informal), sum, na.rm = TRUE)) %>%
ungroup() %>%
add_row(Occupation = "Total",
ocu = sum(.$ocu),
formal = sum(.$formal),
informal = sum(.$informal)) %>%
select(Occupation, ocu, formal, informal) %>%
mutate(across(c(ocu, formal, informal), ~ . / last(ocu)*100))
Occupied_description <- Occupied_description[-c(7),]
Occupied_description <- Occupied_description %>%
mutate(across(c(ocu, formal, informal), ~ sprintf("%.1f", .x)))
stargazer(Occupied_description, summary = FALSE, type = "latex", rownames = FALSE,
out = "2.1.Occupied_description_table.txt")
#------------ DATA CLEANING PROCESS: EXPLORING INCOME --------------------------
#-------------------OBSERVED vs IMPUTED VARIABLES-------------------------------
obs_vars <- c("ie",  "impa", "ingtot", "iof1", "iof2", "iof3h", "iof3i", "iof6", "isa")
imp_vars <- c("iees", "impaes", "ingtotes", "iof1es", "iof2es", "iof3hes", "iof3ies", "iof6es", "isaes")
titles   <- c("Especie", "Main Activity", "Total","Interes and dividends", "Retirement", "Household Aid", "Institutional Aid",
"Real State", "Second Activity")
# ----> PROOF OF: IMPUTED VARIABLES COVER SOME MISSING VALUES OF OBSERVED VARIABLES
imp_vars2 <- c("iees", "imdies", "impaes", "iof1es", "iof2es", "iof3hes", "iof3ies", "iof6es", "isaes")
missing_report <- c("cclasnr4", "cclasnr5", "cclasnr2", "cclasnr6", "cclasnr7", "cclasnr8", "cclasnr8", "cclasnr11", "cclasnr3")
check <- function(db, imp_var, missing_var) {
nrow(db2 %>% filter(!is.na(!!sym(imp_var)), !!sym(missing_var) != 1)) == 0}
# MISSING VALUES OF OBSERVED VALUES ARE COVERED BY IMPUTED VALUES? RETURNS TRUE IF CONDITION IS MET
mapply(function(imp, miss) check(db2, imp, miss), imp_vars2, missing_report); rm(imp_vars2,missing_report)
# ---> FILLING EXTREME MISSING VALUES WITH IMPUTED VALUES
for(i in seq_along(obs_vars)) {
new_name <- paste0(obs_vars[i], "_oi")
# Convert NULL to NA
imp_val <- if (!is.null(db2[[imp_vars[i]]])) db2[[imp_vars[i]]] else rep(NA, nrow(db2))
obs_val <- if (!is.null(db2[[obs_vars[i]]])) db2[[obs_vars[i]]] else rep(NA, nrow(db2))
db2[[new_name]] <- ifelse(!is.na(imp_val), imp_val, obs_val)
}
#-------------- "Y" CONSTRUCTED VARIABLES VS OBSERVES+IMPUTED CORRECTIONS-------
# -----> CHOOSING BETWEEEN MANUEL'S/ IGNACIO VARIABLES AND OBSERVERD+IMPUTED
#  CORRELATION PLOT
db_temp <- db2 %>%
mutate(
Other = ie_oi,
`Total Income` = ingtot_oi,
`Informal Salary` = ifelse(informal == 1, impa_oi, NA),
`Formal Salary` = ifelse(formal == 1, impa_oi, NA),
`Domestic Work` = ifelse(p6240 == 4, impa_oi, NA)
) %>%
select( Other, `Informal Salary`, `Formal Salary`,`Total Income`,`Domestic Work`,
`Y. Others` = y_otros_m,`Y. Informal Salary` = y_gananciaNeta_m,`Y. Formal Salary` = y_ingLab_m,
`Y. Total Income` = y_total_m,`Y. Domestic Work` = y_vivienda_m,
)
db_temp <- db_temp %>%
mutate_all(~ ifelse(is.na(.) | . == 0, 0, 1))
db_temp <-  db_temp %>%  select(which(apply(db_temp, 2, sd) > 0))
M <- cor(db_temp, use = "pairwise.complete.obs")
corrplot(
M, method = "color",         # Use colored squares
col = colorRampPalette(c("lightgray", "white", "blue"))(200),
tl.col = "black", tl.srt = 90,   tl.cex = 0.8, cl.cex = 0.9,
addCoef.col = "black", number.cex = 0.8,mar = c(2,2,2,2))
# ----> CHOOSING SALARY VARIABLES (WORKING AS FIRST ACTIVITY)
db_temp <-  db2 %>% filter(p6240 == 1) %>%  select(y_salary_m, impa_oi)
summary(db_temp)
sapply(db_temp, function(col) sum(col == 0, na.rm = TRUE)) # Number of 0 values
sapply(db_temp, function(col) {
if (is.numeric(col)) { cut(col, breaks = quantile(col, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE), include.lowest = TRUE) %>%
table()
} else {
NA # OBSERVATIONS PER QUANTILE
}
})
# ----> CHOOSING TOTAL INCOME
TOTAL_INCOME <- data.frame(
Metric = c("Mean", "NA Count", "Zero Count", "Q1", "Median", "Q3"),
ingtot_oi = sapply(list(
function(x) mean(x, na.rm = TRUE),
function(x) sum(is.na(x)),
function(x) sum(x == 0, na.rm = TRUE),
function(x) quantile(x, 0.25, na.rm = TRUE),
function(x) median(x, na.rm = TRUE),
function(x) quantile(x, 0.75, na.rm = TRUE)
), function(f) f(db2$ingtot_oi)),
y_total_m = sapply(list(
function(x) mean(x, na.rm = TRUE),
function(x) sum(is.na(x)),
function(x) sum(x == 0, na.rm = TRUE),
function(x) quantile(x, 0.25, na.rm = TRUE),
function(x) median(x, na.rm = TRUE),
function(x) quantile(x, 0.75, na.rm = TRUE)
), function(f) f(db2$y_total_m))
)
TOTAL_INCOME$Difference <- with(TOTAL_INCOME, ingtot_oi - y_total_m)
stargazer(TOTAL_INCOME, summary = FALSE, type = "latex",title = "Total Income variables comparison",
label = "tab:total_income",out = "2.1 TOTAL INCOME.tex")
#------------------ EXTRA VALIDATION -------------------------------------------
# ----> CHECKING DISPERSION OF OBSERVED VS IMPUTED
Stats <- mapply(function(ob, im, title) {
obs <- db2[[ob]]; imp <- db2[[im]]
q_obs <- quantile(obs, c(0.05, 0.25, 0.5, 0.75, 0.95), na.rm = TRUE)
q_imp <- quantile(imp, c(0.05, 0.25, 0.5, 0.75, 0.95), na.rm = TRUE)
data.frame(
Statistic = c("Mean", "SD", "NA values", paste0("Quantile_", c(5, 25, 50, 75, 95))),
Obs = c(mean(obs, na.rm = TRUE), sd(obs, na.rm = TRUE), sum(is.na(obs)), round(q_obs, 2)),
Imp = c(mean(imp, na.rm = TRUE), sd(imp, na.rm = TRUE), sum(is.na(imp)), round(q_imp, 2))
) %>% rename_with(~ paste0(title, "_", sub("^(Obs|Imp)$", "\\1", .x)), Obs:Imp)
}, obs_vars, imp_vars, titles, SIMPLIFY = FALSE)
Obs_vs_Imp <- Reduce(function(x, y) merge(x, y, by = "Statistic", sort = FALSE), Stats)
# ---> DIFFERENCES OBSERVED VS IMPUTED
cols <- 2:ncol(Obs_vs_Imp)
obs_idx <- cols[seq(1, length(cols), by = 2)]
imp_idx <- cols[seq(2, length(cols), by = 2)]
Differences <- Obs_vs_Imp[, imp_idx] - Obs_vs_Imp[, obs_idx]
colnames(Differences) <- titles
Differences <- cbind(Statistic = Obs_vs_Imp[, 1], Differences)
Differences <- Differences[-c(9),]
stargazer(Differences, summary = FALSE, type = "latex", rownames = FALSE,
out = "2.2.Differences Observed vs Imputed.txt")
# ----> OJALÁ SALGA
# -----> EVALUATING DENSITY OF OBSERVED VS OBSERVED +IMPUTED
# obs_vars <- c("ie",  "impa", "ingtot", "iof1", "iof6", "isa")
# obs_imp <- c("ie_oi", "impa_oi", "ingtot_oi", "iof6_oi", "isa_oi")
# titles   <- c("Especie", "Main Activity", "Total","Interes and dividends","Real State", "Second Activity")
#
# par(mfrow = c(2, 5), oma = c(0, 0, 5, 0))
#  for(i in seq_along(obs_vars)) {
#    # Extract observed and imputado data
#    data_obs <- db2[[obs_vars[i]]]
#    data_imp <- db2[[obs_imp[i]]]
#    q_obs <- quantile(data_obs, probs = c(0.05, 0.95), na.rm = TRUE) # Exclude extreme percentiles
#    data_obs <- data_obs[data_obs >= q_obs[1] & data_obs <= q_obs[2]]
#    q_imp <- quantile(data_imp, probs = c(0.05, 0.95), na.rm = TRUE)
#    data_imp <- data_imp[data_imp >= q_imp[1] & data_imp <= q_imp[2]]
#    dens_obs <- density(data_obs, na.rm = TRUE) # Compute density
#    dens_imp <- density(data_imp, na.rm = TRUE)
#
#    xlim <- range(c(dens_obs$x, dens_imp$x), na.rm = TRUE)
#    ylim <- range(c(dens_obs$y, dens_imp$y), na.rm = TRUE)
#
#    plot(dens_obs, xlim = xlim, ylim = ylim,
#         main = titles[i], xlab = "", ylab = "Density",
#         col = "black", lwd = 2, type = "l")
#
#    lines(dens_imp, col = "red", lwd = 2)
#  }
#
#  par(fig = c(0, 1, 0.92, 1), new = TRUE)
#  plot(0, type = "n", axes = FALSE, xlab = "", ylab = "")
#  legend("center", legend = c("Observed", "Imputed"),
#         col = c("black", "red"), lty = 1, horiz = TRUE, bty = "n", cex = 0.8)
# ----------------------DATA STATISTICAL DESCRIPTION ---------------------------
db2 <- db2 %>% mutate(Sexo = case_when(
sex == 0 ~ "Women",
sex == 1 ~ "Men" ))
db2 <- db2 %>% mutate(Sexo = case_when(
sex == 0 ~ "Women",
sex == 1 ~ "Men" ))
# ----> SALARY INCOME: SPOTTING % OF NA's to FILL
WAGES <- db2 %>%
group_by(Occupation, Sexo) %>%
summarise(
mean_age = mean(age, na.rm = TRUE),
Q1_wages = mean(impa_oi[impa_oi <= quantile(impa_oi, 0.25, na.rm = TRUE)], na.rm = TRUE),
mean_wages = mean(impa_oi, na.rm = TRUE),
Q3_wages = mean(impa_oi[impa_oi >= quantile(impa_oi, 0.75, na.rm = TRUE)], na.rm = TRUE),
na_or_zero_percentage_total = sum(is.na(impa_oi) | impa_oi <= 10000) / n() * 100
) %>%
ungroup() %>%
mutate(across(where(is.numeric), ~ round(.x, 0)))
stargazer(WAGES, type = "latex", summary = FALSE, title = "Wage description by Occupation and Sex",
label = "tab:WAGES", out = "2.1 WAGES.tex",
digits = 1)
# ------------------------- FILLING NA's VALUES ---------------------------------
# ---> MAX LEVEL EDU: ONLY 10% MISSING. FILL WITH MODE
mode_edu <- as.numeric(names(sort(table(db2$maxEducLevel), decreasing = TRUE)[1]))
db2 <- db2  %>%
mutate(maxEducLevel = ifelse(is.na(maxEducLevel) == TRUE, mode_edu , maxEducLevel))
# ----> FILLING SALARY VARIABLE.
db2 <- db2 %>% mutate(working = ifelse(p6240 == 1, 1, 0))
db2$maxEducLevel<- factor(db2$maxEducLevel)
dummy_maxEducLevel <- as.data.frame(model.matrix(~ maxEducLevel - 1, data = db2))
db2 <- cbind(db2, dummy_maxEducLevel)
lM1 <- lm(impa_oi ~ formal + working + maxEducLevel, data = db2)
summary(lM1)
# ----> EVALUATING LEVERAGE
db2$leverage <- NA
db2$leverage[as.numeric(names(hatvalues(lM1)))] <- hatvalues(lM1)
db2$residuals <- NA
db2$residuals[as.numeric(names(residuals(lM1)))] <- residuals(lM1)
N <- nrow(db2)
db2$id<- seq(1 , N)
LEV <- ggplot(db2 , aes(y = leverage , x = id , color= Occupation )) +
geom_point() +
theme_bw() +
labs(x = "Observations",
y = "Leverage",
title = "")
RES <- ggplot(db2 , aes(y = leverage , x = residuals, color= Occupation )) +
geom_point() + # add points
theme_bw() + #black and white theme
labs(x = "Residuals",
y = "Leverage",
title = "") # labels
grid.arrange(LEV, RES, ncol = 2)
# CUTTING HIGH LEVERAGE OBSERVATIONS
p <- mean(db2$leverage, na.rm = TRUE)
p
cutt <- 3*p
db2 <-  db2 %>%
dplyr:: filter(leverage<= cutt)
# RE RUNNING THE MODEL
lM2 <- lm(impa_oi ~ formal + working + maxEducLevel, data = db2)
summary(lM2)
db2$impa_oi_P <- predict(lM2, newdata = db2)
db2$impa_oi <- ifelse(is.na(db2$impa_oi) | db2$impa_oi == 0, db2$impa_oi_P, db2$impa_oi)
# ----> CHECKING FOR NEGATIVE VALUES
non_positive_impa_oi <- sum(db2$impa_oi <= 0)
cat("Number of non-positive values in y_salary_m:", non_positive_impa_oi, "\n")
# ----> CHECKING RESIDUALS
png("2.3 Residuals removing HIGH LEVERAGE.png", width = 800, height = 600)
par(mfrow = c(2, 2))
plot(lM2)
dev.off()
rm(db_miss,question, M,Nobs,mode_edu,dummy_maxEducLevel,lM1, Occupied_description,imp_vars,obs_vars,titles,Stats,Obs_vs_Imp, imp_idx,obs_idx,cols, check,lM2,N,WAGES,TOTAL_INCOME,RES,LEV, Differences, db_temp, tables_list, cutt, i, imp_val, new_name, obs_val, p)
# ------------ RUNNING THE REGRESSION ------------------------------------------
model_salary <- lm(log(impa_oi) ~ age + I(age^2), data = db2)
summary(model_salary)
# ------------ EVALUATING RESIDUALS --------------------------------------------
png("3.1 Salary vs Age.png", width = 800, height = 600)
par(mfrow = c(2, 2))
plot(model_salary)
dev.off()
# Is age^2 worth it? Yes it is jeje
model_salary2 <- lm(log(y_salary_m) ~ age, data = db2)
anova(model_salary , model_salary2)
# ------------BOOTSTRAPPING RESULTS --------------------------------------------
set.seed(100)  # For reproducibility
boot_model_salary = do(10000)*lm(log(impa_oi) ~ age + I(age^2),data=mosaic::resample(db2))
boot_summary <- boot_model_salary %>%
summarise(
age = mean(age),
age_se = sd(age),
age_lower = quantile(age, 0.025),
age_upper = quantile(age, 0.975),
age2 = mean(I(age^2)),
age2_se = sd(I(age^2)),
age2_lower = quantile(I(age^2), 0.025),
age2_upper = quantile(I(age^2), 0.975)
)
model_function <- function(data, indices) {
sample_data <- data[indices, ]
model <- lm(log(impa_oi) ~ age + I(age^2), data = sample_data)
return(coef(model))
}
boot_model_salary2 <- boot(db2, model_function, R = 1000)
# BOOTSTRAP STANDAR ERRORS
boot_se <- apply(boot_model_salary2$t, 2, sd)
# ------------ EXPORTING TO LATEX R --------------------------------------------
stargazer( model_salary, model_salary,
type = "latex",se = list(summary(model_salary)$coefficients[, 2], boot_se),
title = "Monthly Income Salary Relation with Age",
covariate.labels = c("Intercept", "Age", "Age Squared"),
dep.var.labels = "Labor Monthly Income*",
column.labels = c("MCO", "Bootstrap"),
star.cutoffs = c(0.1, 0.05, 0.01),
ci = TRUE,
ci.level = 0.95,
out = "Salary and Age.tex",
notes = c("Statistical significance levels: *** p<0.01, ** p<0.05, * p<0.1."),
add.lines = list(c("Method", "MCO", "Bootstrap")
)
)
# ------------ BOOTSTRAPPING FOR PEAK AGE --------------------------------------
peak_age_f <- function(data, indices) {
sample_data <- data[indices, ]
model <- lm(log(impa_oi) ~ age + I(age^2), data = sample_data)
coef_model <- coef(model)
peak_age <- -coef_model["age"] / (2 * coef_model["I(age^2)"])
return(peak_age)
}
set.seed(100)
boot_peak_age <- boot(db2, peak_age_f, R = 1000)
# Calculate confidence intervals for the peak age
peak_age_ci <- boot.ci(boot_peak_age, type = "perc")
print(peak_age_ci)
# ------------ PLOTTING THE AGE-EARNINGS PROFILE --------------------------
# Define a single function to fit the model and calculate peak age
peak_age_f <- function(data, indices) {
sample_data <- data[indices, ]
model <- lm(log(impa_oi) ~ age + I(age^2), data = sample_data)
coef_model <- coef(model)
peak_age <- -coef_model["age"] / (2 * coef_model["I(age^2)"])
return(peak_age)
}
# Run the bootstrap with 1000 samples
set.seed(100)
boot_peak_age <- boot(db2, peak_age_f, R = 1000)
# Calculate confidence intervals for the peak age
peak_age_ci <- boot.ci(boot_peak_age, type = "perc")
print(peak_age_ci)
# Calculate the original peak age using the full dataset
original_peak_age <- peak_age_f(db2, 1:nrow(db2))
cat("Original Peak Age:", round(original_peak_age, 2), "\n")
cat("95% Bootstrap CI for Peak Age:",
round(peak_age_ci$percent[4], 2), "to",
round(peak_age_ci$percent[5], 2), "\n")
# Fit the quadratic model
model_salary <- lm(log(impa_oi) ~ age + I(age^2), data = db2)
# Create a data frame for prediction
age_values <- seq(min(db2$age), max(db2$age), by = 1)
predicted_earnings <- predict(model_salary, newdata = data.frame(age = age_values))
# Create a data frame for ggplot
plot_data <- data.frame(age = age_values, log_salary = predicted_earnings)
# Plot the age-earnings profile with the peak age and its confidence interval
ggplot(plot_data, aes(x = age, y = log_salary)) +
geom_line(color = "blue", size = 1) +
geom_vline(xintercept = original_peak_age, color = "red", linetype = "dashed") +
geom_vline(xintercept = peak_age_ci$percent[4], color = "green", linetype = "dotted") +
geom_vline(xintercept = peak_age_ci$percent[5], color = "green", linetype = "dotted") +
labs(title = "Estimated Age-Earnings Profile",
x = "Age",
y = "Log(Monthly Income Salary)",
subtitle = paste("Peak Age:", round(original_peak_age, 2),
"95% CI [",
round(peak_age_ci$percent[4], 2), ",",
round(peak_age_ci$percent[5], 2), "]")) +
theme_minimal()
# We are transforming the 'sex' variable to create a new 'Female' indicator where
#female = 1 for females (sex = 0) and Female = 0 for males (sex = 1) (According to data dictionary)
db2 <- db2 %>%
mutate(female = ifelse(sex == 0, 1, 0))
head(db2)
# Checking and removing non-positive values in y_salary_m
non_positive_y_salary_m <- sum(db2$y_salary_m <= 0)
cat("Number of non-positive values in y_salary_m:", non_positive_y_salary_m, "\n")
db2 <- db2 %>% filter(y_salary_m > 0)
model_unconditional <- lm(log(y_salary_m) ~ female, data = db2)
summary(model_unconditional)
#  GAUSS MARCOV THEOREM
#  Linearity Check:
ggplot(data = data.frame(Fitted = fitted(model_unconditional), Residuals = residuals(model_unconditional)),
aes(x = Fitted, y = Residuals)) +
geom_point() +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residuals vs Fitted Values", x = "Fitted Values", y = "Residuals")
# Exogeneity: Mean of residuals should be zero
mean(residuals(model_unconditional))
# Homoscedasticity: Breusch-Pagan Test
bptest(model_unconditional)  #P-value < 0.05 suggests rejecting the null hypothesis
# No Autocorrelation: Durbin-Watson Test
dwtest(model_unconditional) # P-value < 0.05 suggests rejecting the null hypothesis
# Conditional Gender Wage Gap (OLS)
conditional_model <- lm(log(y_salary_m) ~ female + age + I(age^2) + maxEducLevel + informal + estrato1, data = db2)
summary(conditional_model)
# ------------------------ FRISCH-WAUGH-LOVELL THEOREM--------------------------------
#Estimation with FWL to isolate the effect of female on log(salary) by partialling out the control variables.
# Fit the control model (without female)
controls <- lm(log(y_salary_m) ~ age + I(age^2) + maxEducLevel + informal + estrato1, data = db2)
residuals_w <- residuals(controls)
gender <- lm(female ~ age + I(age^2) + maxEducLevel + informal + estrato1, data = db2)
residuals_x <- residuals(gender)
#The effect of female using the residuals
fwl_model_1 <- lm(residuals_w ~ residuals_x)
summary_fwl <- summary(fwl_model_1)
summary_fwl
#  GAUSS MARCOV THEOREM
# 1. Linearity Check: Residual vs Fitted Plot
ggplot(data = data.frame(Fitted = fitted(model_unconditional), Residuals = residuals(fwl_model_1)),
aes(x = Fitted, y = Residuals)) +
geom_point() +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residuals vs Fitted Values", x = "Fitted Values", y = "Residuals")
# 2. Exogeneity: Mean of residuals should be zero
mean(residuals(fwl_model_1)) # Mean is aprox. 0 supporting the assumption of exogeneity
# 3. Homoscedasticity: Breusch-Pagan Test
bptest(fwl_model_1)  #P-value > 0.05 suggests no strong evidence of heteroscedasticity in the residuals
# 4. No Autocorrelation: Durbin-Watson Test
dwtest(fwl_model_1) # #P-value < 0.05 suggests rejecting the null hypothesis
# 5. Multicollinearity
vif_values <- vif(conditional_model)
vif_values #Multicollinearity is moderate to high for age and I(age^2) (GVIF^(1/(2*Df)) > 5), which is expected because I(age^2) is a transformation of age. The other variables do not exhibit multicollinearity.
robust_se <- coeftest(fwl_model_1, vcov = vcovHC(fwl_model_1, type = "HC1"))
print(robust_se)
#The model shows a highly significant negative effect of being female on salary,
#with a coefficient of -0.217. The standard error for this coefficient is small (0.0113),
#indicating precise estimation, the intercept is not significant, which is expected since
#residuals are used and finally the robust standard errors suggest the model has effectively addressed
#autocorrelation issues, providing solid and reliable results.
# ------------------------ FWL WITH BOOTSTRAP ----------------------------------------
# Función de bootstrap para FWL
# Función de bootstrap para FWL
fwl_bootstrap <- function(data, indices) {
# Resample the data
boot_data <- data[indices, ]
control_model_boot <- lm(log(y_salary_m) ~ age + maxEducLevel + informal + estrato1, data = boot_data)
boot_data$residuals_control <- residuals(control_model_boot)
fwl_model_boot <- lm(residuals_control ~ female, data = boot_data)
return(c(coef(fwl_model_boot)["female"]))
}
# Bootstrap with 1000 resamples
set.seed(100)  # For reproducibility
fwl_boot_results <- boot(data = db2, statistic = fwl_bootstrap, R = 1000)
# Ajustar el modelo fuera de la función de bootstrap para pruebas y gráficos
control_model <- lm(log(y_salary_m) ~ age + maxEducLevel + informal + estrato1, data = db2)
db2$residuals_control <- residuals(control_model)
fwl_boot_model <- lm(residuals_control ~ female, data = db2)
summary(fwl_boot_model)
#  GAUSS MARKOV THEOREM
# 1. Linearity Check: Residual vs Fitted Plot
ggplot(data = data.frame(Fitted = fitted(fwl_boot_model), Residuals = residuals(fwl_boot_model)),
aes(x = Fitted, y = Residuals)) +
geom_point() +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residuals vs Fitted Values", x = "Fitted Values", y = "Residuals")
# 2. Exogeneity: Mean of residuals should be zero
mean_residuals <- mean(residuals(fwl_boot_model)) # Mean is approx. 0 supporting the assumption of exogeneity
print(mean_residuals)
# 3. Homoscedasticity: Breusch-Pagan Test
bp_test <- bptest(fwl_boot_model)  # P-value < 0.05 suggests rejecting the null hypothesis, and evidence of hero
print(bp_test)
# 4. No Autocorrelation: Durbin-Watson Test
dw_test <- dwtest(fwl_boot_model) # P-value < 0.05 suggests rejecting the null hypothesis
print(dw_test)
# Comparando los resultados
boot_se <- sd(boot_estimates)
boot_model_salary2 <- boot(db2, model_function, R = 1000)
View(boot_model_salary2)
