---
title: "Taller 1 - BD&ML Grupo 7"
author: "Grupo 7"
date: "2025-02-02"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
gc(rm(list = ls()))

knitr::opts_chunk$set(echo = TRUE)

require(pacman)
p_load(stringr, # html to text
       tidyverse, # tidy-data
       skimr, # summary data
       rvest, # Web scrapping
       dplyr, # managing tables
       corrplot,#Correlation plot
       reshape2,# Long format for tables 
       boot)  
```

## 1. Introduction

In the public sector, accurate reporting of individual income is
critical for computing taxes. However, tax fraud of all kinds has always
been a significant issue. According to the Internal Revenue Service
(IRS), about 83.6% of taxes are paid voluntarily and on time in the
US.1. One of the causes of this gap is the under-reporting of incomes by
individuals. An income predicting model could potentially assist in
agging cases of fraud that could lead to the reduction of the gap.
Furthermore, an income prediction model can help identify vulnerable
individuals and families that may need further assistance.

The objective of the problem set is to generate a predictive model on
income levels based on Bogota's information about employed adults (\>18
years old). Thus, we can predict levels of income and then estimate a
level of tax payment. For this objective the survey of 2018 GEIH from
DANE, will be used.

(Describe the process of acquiring the data and if there are any
restrictions to accessing/scraping these data.) For scrapping this data
we will use ignaciomsarmiento repository and rvest to read the htmls. As
this data frames are html tables, we will also use dplyr.

<div>

```{r Scrapping}
    # Link
    base <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_"
    htmls <- paste0(base,"page_",1:10, ".html")

    tables_list <- list()
    for (url in htmls) {
      web_page <- read_html(url)
      table <- web_page %>%
        html_nodes("table.table-striped") %>%
        html_table(fill = TRUE)
      tables_list[[url]] <- table
    }

    db = bind_rows(tables_list) %>% select(-...1)
    rm(tables_list,web_page,table,base,htmls,url)
```

</div>

2.  Describe the data briefly, including its purpose, and any other
    relevant information.

## 2. Data proccessing

We will use the definition the variable "ocu" already included on the data set 
which takes value 1 if the person is occupied (employed) and 0 otherwise.

```{r Cleaning of data set, echo=FALSE}
# Filtering > 18 and occupied
db2 <- db %>% filter(age > 18, ocu == 1)

# Framing Missing Values
Nobs <- nrow(db2) 
db_miss <- data.frame(
  Variable = names(db2),
  n_missing = colSums(is.na(db2)),
  p_missing = round(colSums(100*is.na(db2))/Nobs,2)
) 
rownames(db_miss) <- NULL

# Attaching question content
question <- read_html("https://ignaciomsarmiento.github.io/GEIH2018_sample/dictionary.html")
question <- question %>%
        html_nodes("table") %>%
        html_table(fill = TRUE)
question = bind_rows(question)
db_miss <- left_join(question, db_miss, by = "Variable")
db_miss <- db_miss %>% arrange(desc(p_missing)) %>% filter(p_missing != 0) 

# As we can see, almost 99/177 variables have more than 20% of the sample missing. 
# Yet, many of these variables are associated with non-occupied people and are not
# relevant for this exercise. Others, are the same variable with different scales 
# (example: monthly salary vs hourly salary). Thus, we're only going to keep the following variables:

db2 <- db2 %>%
  select(p6750,p7505, y_ingLab_m, y_salary_m, y_total_m, impa, isa, iof1, iof2, iof3h, iof3i, iof6, 
         ingtotes, ingtotob, ingtot, y_bonificaciones_m, y_gananciaNeta_m, 
         y_gananciaNetaAgro_m, y_primaNavidad_m, y_primaServicios_m, y_primaVacaciones_m, 
         maxEducLevel, directorio, secuencia_p, orden, clase, dominio, mes, estrato1, 
         sex, age, p6050, p6090, p6100, oficio, fex_c, depto, fex_dpto, fweight, informal)

# For trying to avoid colinearity, we're going to check if two variables contain the same information.
# so that we only keep the most relevant one.
db3 <- db2 %>% mutate_all(~ifelse(!is.na(.), 1, 0))
db3 <-  db3 %>%  select(which(apply(db3, 2, sd) > 0))

M <- cor(db3)
corrplot(M,tl.cex = 0.7, cl.cex = 0.8) 
M_long <-melt(M,na.rm = TRUE)
M_long <- M_long %>%
  filter(abs(value) > 0.4, Var1 != Var2) %>%  
  arrange(desc(abs(value)))

# We can see p6750 has perfect correlation with y_gananciaNeta_m and y_salary_m and y_ingLab_m 
# Thus, as p6750 as 70% of p6750 values are missing we're going to drop this variable. 

db2 <- db2 %>% select(-p6750)

# Deciding between y_salary_m and y_ingLab_M. For this, we're going to evaluate the values the variable takes on the following quanties.
quantiles <- c(0, 0.25, 0.50, 0.75, 1.0)
quant_table <- as.data.frame(t(sapply(list(y_salary_m = db2$y_salary_m, 
                                           y_ingLab_m = db2$y_ingLab_m), 
                                      quantile, probs = quantiles, na.rm = TRUE)))

# Add a row for the number of NAs
quant_table <- rbind(quant_table, "NAs_y_salary_m" = sum(is.na(db2$y_salary_m)))
quant_table <- rbind(quant_table, "NAs_y_ingLab_m" = sum(is.na(db2$y_ingLab_m)))
print(quant_table)

# As differences between this two variables are considerable on the last chuck (the highest incomes) we're not going to remove them, before working with it's NAs values.

# As 40.32% of the values are missing we're going to fill the missing values using Level of Education 
# as a proxy (Mincer, 1958)

# Max - Level of Education.
# Filling with mean as only 10% of values are missing
mode_edu <- as.numeric(names(sort(table(db2$maxEducLevel), decreasing = TRUE)[1]))
db2 <- db2  %>%
  mutate(maxEducLevel = ifelse(is.na(maxEducLevel) == TRUE, mode_edu , maxEducLevel))

# Creating the dummy variable for regressing over y_salary_m and y_ingLab_m
db2$maxEducLevel<- factor(db2$maxEducLevel)
dummy_maxEducLevel <- as.data.frame(model.matrix(~ maxEducLevel - 1, data = db2))
db2 <- cbind(db2, dummy_maxEducLevel)


### y_salary_m
lM1 <- lm(y_salary_m ~ ingtot + sex+ maxEducLevel3 + maxEducLevel4 + maxEducLevel5 + maxEducLevel6 + maxEducLevel7 , data = db2)
summary(lM1)
db2$y_salary_m_P <- predict(lM1, newdata = db2)
db2 <-  db2 %>%  mutate(y_salary_m = ifelse(is.na(y_salary_m), y_salary_m_P, y_salary_m))

### y_ingLab_m
lM2 <- lm(y_ingLab_m ~ ingtot + sex+ maxEducLevel3 + maxEducLevel4 + maxEducLevel5 + maxEducLevel6 + maxEducLevel7 , data = db2)
summary(lM2)
db2$y_ingLab_m <- predict(lM1, newdata = db2)
db2 <-  db2 %>%  mutate(y_ingLab_m = ifelse(is.na(y_ingLab_m), y_ingLab_m, y_salary_m))

# Checking and removing non-positive values in y_salary_m
non_positive_y_salary_m <- sum(db2$y_salary_m <= 0)
cat("Number of non-positive values in y_salary_m:", non_positive_y_salary_m, "\n")
db2 <- db2 %>% filter(y_salary_m > 0)

## drop recently created variables
db<-  db %>% select(- maxEducLevel1, - maxEducLevel2, - maxEducLevel3, - maxEducLevel4, - maxEducLevel5, - maxEducLevel6, - maxEducLevel7,-predicted_y )

rm(db3,db_miss,question, M, M_long,q3_salary,q3_ingLab,filtered_salary, filtered_ingLab,Nobs)
```

3.  Describe the data cleaning process
4.  Descriptive the variables included in your analysis.

At a minimum, you should include a descriptive statistics table with its
interpretation. However, I expect a deep analysis that helps the reader
understand the data, its variation, and the justification for your data
choices. Use your professional knowledge to add value to this section.
Do not present it as a "\\dry" list of ingredients

## 3. Age wage profile

```{r Age wage Regression, echo=FALSE}
```



## 4. The gender earnings
```{r Unconditional Gender Wage Gap}

# We are transforming the 'sex' variable to create a new 'Female' indicator where
#female = 1 for females (sex = 0) and Female = 0 for males (sex = 1) (According to data dictionary)

db2 <- db2 %>%
  mutate(female = ifelse(sex == 0, 1, 0)) 
head(db2)

model_unconditional <- lm(log(y_salary_m) ~ female, data = db2)
summary(model_unconditional)


#Gauss-Markov Theorem
#  Linearity Check:
ggplot(data = data.frame(Fitted = fitted(model_unconditional), Residuals = residuals(model_unconditional)), 
       aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Residuals vs Fitted Values", x = "Fitted Values", y = "Residuals")

# Exogeneity: Mean of residuals should be zero
mean(residuals(model_unconditional))

# Homoscedasticity: Breusch-Pagan Test
bptest(model_unconditional)  #P-value < 0.05 suggests rejecting the null hypothesis

# No Autocorrelation: Durbin-Watson Test
dwtest(model_unconditional) # P-value < 0.05 suggests rejecting the null hypothesis

```
The statistical significance of the model is evident from the extremely low p-values associated with both the Breusch-Pagan test for heteroscedasticity and the Durbin-Watson test for autocorrelation These results indicate strong evidence against the null hypotheses, revealing violations in the homoscedasticity and independence of errors assumptions, respectively. Economically, the model's findings suggest that the gender variable (female) plays a significant role in explaining variations in the log-transformed salary, highlighting potential gender disparities in earnings, however, the presence of heteroscedasticity and autocorrelation implies that traditional inference may be flawed, necessitating robust econometric techniques to ensure the validity of the estimated effects. Therefore, while the model provides important insights into gender-based salary differences, addressing the identified econometric issues is crucial for drawing precise and actionable economic conclusions.

```{r Conditional Gender Wage Gap}

# Conditional Gender Wage Gap
conditional_model <- lm(log(y_salary_m) ~ female + age + I(age^2) + maxEducLevel + informal+estrato1, data = db2)
summary(conditional_model)

#Estimation with Frisch-Waugh-Lovell Theorem (FWL)
# Fit the control model (without female)
controls <- lm(log(y_salary_m) ~ age + I(age^2) + maxEducLevel + informal + estrato1, data = db2)
residuals_w <- residuals(controls)

gender <- lm(female ~ age + I(age^2) + maxEducLevel + informal + estrato1, data = db2)
residuals_x <- residuals(gender)

#The effect of female using the residuals
fwl_model_1 <- lm(residuals_w ~ residuals_x)
summary_fwl <- summary(fwl_model_1)  
summary_fwl

#Gauss-Markov Theorem 
# 1. Linearity Check: Residual vs Fitted Plot
ggplot(data = data.frame(Fitted = fitted(model_unconditional), Residuals = residuals(fwl_model_1)), 
       aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Residuals vs Fitted Values", x = "Fitted Values", y = "Residuals")

# 2. Exogeneity: Mean of residuals should be zero
mean(residuals(fwl_model_1))

# 3. Homoscedasticity: Breusch-Pagan Test
bptest(fwl_model_1)  #P-value < 0.05 suggests rejecting the null hypothesis

# 4. No Autocorrelation: Durbin-Watson Test
dwtest(fwl_model_1) # #P-value < 0.05 suggests rejecting the null hypothesis

# Performing the bootstrap
fwl_bootstrap <- function(data, indices) {
  # Resample the data
  boot_data <- data[indices, ]
  control_model_boot <- lm(log(y_salary_m) ~ age + maxEducLevel + informal + estrato1, data = boot_data)
  boot_data$residuals_control <- residuals(control_model_boot)
  fwl_model_boot <- lm(residuals_control ~ female, data = boot_data)
  return(coef(fwl_model_boot)["female"])
}

# Bootstrap with 1000 resamples
set.seed(100)  # For reproducibility
fwl_boot_results <- boot(data = db2, statistic = fwl_bootstrap, R = 1000)

# Bootstrap estimate and standard error
boot_estimates <- fwl_boot_results$t
boot_se <- sd(boot_estimates)
boot_mean <- mean(boot_estimates)

# Comparing the results
results <- data.frame(
  Method = c("FWL", "Bootstrap"),
  Estimate = c(coef(fwl_model_1)["residuals_x"], boot_mean),
  StdError = c(summary_fwl$coefficients["residuals_x", "Std. Error"], boot_se)
)
print(results)

#Cross-validation
control <- trainControl(method = "cv", number = 10)
cv_model <- train(log(y_salary_m) ~ female + age + I(age^2) + maxEducLevel + informal + estrato1, data = db2, method = "lm", trControl = control)
print(cv_model)

```
```{r Peak ages}

# Regression model with age-gender interaction
peak_ages_model <- lm(log(y_salary_m) ~ age * female + I(age^2) * female + maxEducLevel + informal + estrato1, data = db2)

# Create a range of ages and genders for prediction
age_seq <- seq(min(db2$age), max(db2$age), by = 1)
prediction_data <- expand.grid(age = age_seq, female = c(0, 1))

# Assign typical values for other variables
common_educ <- names(sort(table(db2$maxEducLevel), decreasing = TRUE))[1]  # Mode of education
common_informal <- as.numeric(names(sort(table(db2$informal), decreasing = TRUE))[1])  # Mode of informality
common_estrato <- as.numeric(names(sort(table(db2$estrato1), decreasing = TRUE))[1])  # Mode of socioeconomic level

# Add fixed values to prediction_data
prediction_data$maxEducLevel <- factor(common_educ, levels = levels(db2$maxEducLevel))
prediction_data$informal <- common_informal
prediction_data$estrato1 <- common_estrato

# Make predictions with confidence intervals
predictions <- predict(peak_ages_model, newdata = prediction_data, interval = "confidence")
prediction_data <- cbind(prediction_data, predictions)

# Back-transform log wages to actual wages for plotting
prediction_data <- prediction_data %>%
  mutate(pred_wage = exp(fit), 
         lwr_wage = exp(lwr), 
         upr_wage = exp(upr))


# Plot predicted age-wage profile by gender
ggplot(prediction_data, aes(x = age, y = pred_wage, color = as.factor(female), fill = as.factor(female))) +
  geom_line(linewidth = 1) +  # Use linewidth instead of size
  geom_ribbon(aes(ymin = lwr_wage, ymax = upr_wage), alpha = 0.2) +
  labs(title = "Predicted Age-Wage Profile by Gender",
       subtitle = "Includes confidence intervals based on regression estimates",
       x = "Age",
       y = "Predicted Wage",
       color = "Gender",
       fill = "Gender",
       caption = "Note: The predicted age-wage profile is estimated using a regression model with interaction terms.\nConfidence intervals reflect the uncertainty of predictions.\nSource: Own estimations based on regression model.") +
  scale_color_manual(values = c("blue", "pink"), labels = c("Male", "Female")) +
  scale_fill_manual(values = c("blue", "pink"), labels = c("Male", "Female")) +
  theme_minimal() +
  theme(plot.caption = element_text(hjust = 0, size = 10))  # Left-align caption for readability

# Extract coefficients from the model
coefficients <- coef(peak_ages_model)

# Definir los coeficientes necesarios
age_coef <- coefficients["age"]
age_squared_coef <- coefficients["I(age^2)"]
female_age_coef <- coefficients["age:female"]
female_age_squared_coef <- coefficients["female:I(age^2)"]

# Calcular las edades de pico si los coeficientes estÃ¡n presentes
if (all(!is.na(c(age_coef, age_squared_coef, female_age_coef, female_age_squared_coef)))) {
  peak_age_male <- round(-age_coef / (2 * age_squared_coef))
  peak_age_female <- round(-(age_coef + female_age_coef) / (2 * (age_squared_coef + female_age_squared_coef)))
  
  cat("Peak age for males:", peak_age_male, "\n")
  cat("Peak age for females:", peak_age_female, "\n")
} else {
  cat("Missing coefficients for calculation.\n")
}

```

